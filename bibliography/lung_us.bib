@article{sartori_tele-echography_2019,
	title = {Tele-echography using a two-layer teleoperation algorithm with energy scaling},
	volume = {2019-May},
	issn = {10504729},
	doi = {10.1109/ICRA.2019.8794152},
	abstract = {Performing ultrasound procedures from a remote site is a challenging task since both a stable behavior, for the safety of the patient, and a high-level of usability, to exploit the sonographer's expertise, need to be guaranteed. Furthermore, a teleoperation system that provides such requirements has to deal with communication delays as well. To address this issue, we use the two-layer algorithm: a passivity-based bilateral teleoperation architecture able to guarantee stability despite unknown and time-varying delay. Its flexibility allows to implement different kinds of control laws. In a Tele-Echography system, the slave manipulator has to apply significant forces needed by the procedure whereas the haptic device at the master side should be very light to avoid tiring the operator. Therefore, the energy needed by these two robots to perform their movements is very different and the energy injected into the system by the operator is often not sufficient to implement the desired action at the slave side. Methods to overcome this problem require to perfectly know the dynamical models of the robots. The solution proposed in this paper does not require such knowledge and is based on properly scaling the energy exchanged between the master and the slave side. We show the effectiveness of this approach in a real setup using a TOUCH haptic device and a WAM Barrett robot holding an ultrasound probe.},
	journal = {Proceedings - IEEE International Conference on Robotics and Automation},
	author = {Sartori, Enrico and Tadiello, Carlo and Secchi, Cristian and Muradore, Riccardo},
	month = may,
	year = {2019},
	note = {ISBN: 9781538660263
Publisher: Institute of Electrical and Electronics Engineers Inc.},
	pages = {1569--1575},
}

@article{soldati_proposal_2020,
	title = {Proposal for {International} {Standardization} of the {Use} of {Lung} {Ultrasound} for {Patients} {With} {COVID}-19},
	volume = {39},
	issn = {1550-9613},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1002/jum.15285 https://onlinelibrary.wiley.com/doi/abs/10.1002/jum.15285 https://onlinelibrary.wiley.com/doi/10.1002/jum.15285},
	doi = {10.1002/JUM.15285},
	abstract = {Growing evidence is showing the usefulness of lung ultrasound in patients with the 2019 new coronavirus disease (COVID-19). Severe acute respiratory syndrome coronavirus 2 has now spread in almost every country in the world. In this study, we share our experience and propose a standardized approach to optimize the use of lung ultrasound in patients with COVID-19. We focus on equipment, procedure, classification, and data sharing.},
	number = {7},
	journal = {Journal of Ultrasound in Medicine},
	author = {Soldati, Gino and Smargiassi, Andrea and Inchingolo, Riccardo and Buonsenso, Danilo and Perrone, Tiziano and Briganti, Domenica Federica and Perlini, Stefano and Torri, Elena and Mariani, Alberto and Mossolani, Elisa Eleonora and Tursi, Francesco and Mento, Federico and Demi, Libertario},
	month = jul,
	year = {2020},
	pmid = {32227492},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {19, care ultrasound, COVID, lung ultrasound, of, point, scoring system},
	pages = {1413--1419},
}

@article{al-zogbi_autonomous_2021,
	title = {Autonomous {Robotic} {Point}-of-{Care} {Ultrasound} {Imaging} for {Monitoring} of {COVID}-19–{Induced} {Pulmonary} {Diseases}},
	volume = {8},
	issn = {22969144},
	url = {www.frontiersin.org},
	doi = {10.3389/FROBT.2021.645756/BIBTEX},
	abstract = {The COVID-19 pandemic has emerged as a serious global health crisis, with the predominant morbidity and mortality linked to pulmonary involvement. Point-of-Care ultrasound (POCUS) scanning, becoming one of the primary determinative methods for its diagnosis and staging, requires, however, close contact of healthcare workers with patients, therefore increasing the risk of infection. This work thus proposes an autonomous robotic solution that enables POCUS scanning of COVID-19 patients’ lungs for diagnosis and staging. An algorithm was developed for approximating the optimal position of an ultrasound probe on a patient from prior CT scans to reach predefined lung infiltrates. In the absence of prior CT scans, a deep learning method was developed for predicting 3D landmark positions of a human ribcage given a torso surface model. The landmarks, combined with the surface model, are subsequently used for estimating optimal ultrasound probe position on the patient for imaging infiltrates. These algorithms, combined with a force–displacement profile collection methodology, enabled the system to successfully image all points of interest in a simulated experimental setup with an average accuracy of 20.6 ± 14.7 mm using prior CT scans, and 19.8 ± 16.9 mm using only ribcage landmark estimation. A study on a full torso ultrasound phantom showed that autonomously acquired ultrasound images were 100\% interpretable when using force feedback with prior CT and 88\% with landmark estimation, compared to 75 and 58\% without force feedback, respectively. This demonstrates the preliminary feasibility of the system, and its potential for offering a solution to help mitigate the spread of COVID-19 in vulnerable environments.},
	journal = {Frontiers in Robotics and AI},
	author = {Al-Zogbi, Lidia and Singh, Vivek and Teixeira, Brian and Ahuja, Avani and Bagherzadeh, Pooyan Sahbaee and Kapoor, Ankur and Saeidi, Hamed and Fleiter, Thorsten and Krieger, Axel},
	month = may,
	year = {2021},
	note = {Publisher: Frontiers Media S.A.},
	keywords = {force feedback, 3D deep convolutional network, 3D landmark estimation, autonomous robotics, COVID-19, point-of-care ultrasound},
	pages = {645756},
}

@article{tsumura_tele-operative_2021,
	title = {Tele-{Operative} {Low}-{Cost} {Robotic} {Lung} {Ultrasound} {Scanning} {Platform} for {Triage} of {COVID}-19 {Patients}},
	volume = {6},
	issn = {23773766},
	doi = {10.1109/LRA.2021.3068702},
	abstract = {Novel severe acute respiratory syndrome coronavirus 2 (COVID-19) has become a pandemic of epic proportions, and global response to prepare health systems worldwide is of utmost importance. 2-dimensional (2D) lung ultrasound (LUS) has emerged as a rapid, noninvasive imaging tool for diagnosing COVID-19 infected patients. Concerns surrounding LUS include the disparity of infected patients and healthcare providers, and importantly, the requirement for substantial physical contact between the patient and operator, increasing the risk of transmission. New variants of COVID-19 will continue to emerge; therefore, mitigation of the virus's spread is of paramount importance. A tele-operative robotic ultrasound platform capable of performing LUS in COVID-19 infected patients may be of significant benefit, especially in low- and middle-income countries. The authors address the issues mentioned above surrounding the use of LUS in COVID-19 infected patients and the potential for extension of this technology in a resource-limited environment. Additionally, first-time application, feasibility, and safety were validated in healthy subjects. Preliminary results demonstrate that our platform allows for the successful acquisition and application of robotic LUS in humans.},
	number = {3},
	journal = {IEEE Robotics and Automation Letters},
	author = {Tsumura, Ryosuke and Hardin, John W. and Bimbraw, Keshav and Grossestreuer, Anne V. and Odusanya, Olushola S. and Zheng, Yihao and Hill, Jeffrey C. and Hoffmann, Beatrice and Soboyejo, Winston and Zhang, Haichong K.},
	month = jul,
	year = {2021},
	note = {Publisher: Institute of Electrical and Electronics Engineers Inc.},
	keywords = {robotic ultrasound, Lung ultrasound, teleoperation},
	pages = {4664--4671},
}

@article{ye_feasibility_2021,
	title = {Feasibility of a {5G}-{Based} {Robot}-{Assisted} {Remote} {Ultrasound} {System} for {Cardiopulmonary} {Assessment} of {Patients} {With} {Coronavirus} {Disease} 2019},
	volume = {159},
	issn = {0012-3692},
	doi = {10.1016/J.CHEST.2020.06.068},
	abstract = {Background: Traditional methods for cardiopulmonary assessment of patients with coronavirus disease 2019 (COVID-19) pose risks to both patients and examiners. This necessitates a remote examination of such patients without sacrificing information quality. Research Question: The goal of this study was to assess the feasibility of a 5G-based robot-assisted remote ultrasound system in examining patients with COVID-19 and to establish an examination protocol for telerobotic ultrasound scanning. Study Design and Methods: Twenty-three patients with COVID-19 were included and divided into two groups. Twelve were nonsevere cases, and 11 were severe cases. All patients underwent a 5G-based robot-assisted remote ultrasound system examination of the lungs and heart following an established protocol. Distribution characteristics and morphology of the lung and surrounding tissue lesions, left ventricular ejection fraction, ventricular area ratio, pericardial effusion, and examination-related complications were recorded. Bilateral lung lesions were evaluated by using a lung ultrasound score. Results: The remote ultrasound system successfully and safely performed cardiopulmonary examinations of all patients. Peripheral lung lesions were clearly evaluated. Severe cases of COVID-19 had significantly more diseased regions (median [interquartile range], 6.0 [2.0-11.0] vs 1.0 [0.0-2.8]) and higher lung ultrasound scores (12.0 [4.0-24.0] vs 2.0 [0.0-4.0]) than nonsevere cases of COVID-19 (both, P {\textless}.05). One nonsevere case (8.3\%; 95\% CI, 1.5-35.4) and three severe cases (27.3\%; 95\% CI, 9.7-56.6) were complicated by pleural effusions. Four severe cases (36.4\%; 95\% CI, 15.2-64.6) were complicated by pericardial effusions (vs 0\% of nonsevere cases, P {\textless}.05). No patients had significant examination-related complications. Interpretation: Use of the 5G-based robot-assisted remote ultrasound system is feasible and effectively obtains ultrasound characteristics for cardiopulmonary assessment of patients with COVID-19. By following established protocols and considering medical history, clinical manifestations, and laboratory markers, this system might help to evaluate the severity of COVID-19 remotely.},
	number = {1},
	journal = {Chest},
	author = {Ye, Ruizhong and Zhou, Xianlong and Shao, Fei and Xiong, Linfei and Hong, Jun and Huang, Haijun and Tong, Weiwei and Wang, Jing and Chen, Shuangxi and Cui, Ailin and Peng, Chengzhong and Zhao, Yan and Chen, Legao},
	month = jan,
	year = {2021},
	pmid = {32653568},
	note = {Publisher: Elsevier},
	keywords = {COVID-19, lung diseases, robotics, telemedicine, ultrasound},
	pages = {270--281},
}

@article{akbari_robotic_2021,
	title = {Robotic {Ultrasound} {Scanning} {With} {Real}-{Time} {Image}-{Based} {Force} {Adjustment}: {Quick} {Response} for {Enabling} {Physical} {Distancing} {During} the {COVID}-19 {Pandemic}},
	volume = {8},
	issn = {22969144},
	url = {www.frontiersin.org},
	doi = {10.3389/FROBT.2021.645424/BIBTEX},
	abstract = {During an ultrasound (US) scan, the sonographer is in close contact with the patient, which puts them at risk of COVID-19 transmission. In this paper, we propose a robot-assisted system that automatically scans tissue, increasing sonographer/patient distance and decreasing contact duration between them. This method is developed as a quick response to the COVID-19 pandemic. It considers the preferences of the sonographers in terms of how US scanning is done and can be trained quickly for different applications. Our proposed system automatically scans the tissue using a dexterous robot arm that holds US probe. The system assesses the quality of the acquired US images in real-time. This US image feedback will be used to automatically adjust the US probe contact force based on the quality of the image frame. The quality assessment algorithm is based on three US image features: correlation, compression and noise characteristics. These US image features are input to the SVM classifier, and the robot arm will adjust the US scanning force based on the SVM output. The proposed system enables the sonographer to maintain a distance from the patient because the sonographer does not have to be holding the probe and pressing against the patient's body for any prolonged time. The SVM was trained using bovine and porcine biological tissue, the system was then tested experimentally on plastisol phantom tissue. The result of the experiments shows us that our proposed quality assessment algorithm successfully maintains US image quality and is fast enough for use in a robotic control loop.},
	journal = {Frontiers in Robotics and AI},
	author = {Akbari, Mojtaba and Carriere, Jay and Meyer, Tyler and Sloboda, Ron and Husain, Siraj and Usmani, Nawaid and Tavakoli, Mahdi},
	month = mar,
	year = {2021},
	note = {Publisher: Frontiers Media S.A.},
	keywords = {artificial intelligence, medical image quality assessment, medical robotic, robotics for COVID-19, ultrasound scanning},
	pages = {645424},
}

@article{jiang_robotic_2023,
	title = {Robotic ultrasound imaging: {State}-of-the-art and future perspectives},
	volume = {89},
	issn = {1361-8415},
	doi = {10.1016/J.MEDIA.2023.102878},
	abstract = {Ultrasound (US) is one of the most widely used modalities for clinical intervention and diagnosis due to the merits of providing non-invasive, radiation-free, and real-time images. However, free-hand US examinations are highly operator-dependent. Robotic US System (RUSS) aims at overcoming this shortcoming by offering reproducibility, while also aiming at improving dexterity, and intelligent anatomy and disease-aware imaging. In addition to enhancing diagnostic outcomes, RUSS also holds the potential to provide medical interventions for populations suffering from the shortage of experienced sonographers. In this paper, we categorize RUSS as teleoperated or autonomous. Regarding teleoperated RUSS, we summarize their technical developments, and clinical evaluations, respectively. This survey then focuses on the review of recent work on autonomous robotic US imaging. We demonstrate that machine learning and artificial intelligence present the key techniques, which enable intelligent patient and process-specific, motion and deformation-aware robotic image acquisition. We also show that the research on artificial intelligence for autonomous RUSS has directed the research community toward understanding and modeling expert sonographers’ semantic reasoning and action. Here, we call this process, the recovery of the “language of sonography”. This side result of research on autonomous robotic US acquisitions could be considered as valuable and essential as the progress made in the robotic US examination itself. This article will provide both engineers and clinicians with a comprehensive understanding of RUSS by surveying underlying techniques. Additionally, we present the challenges that the scientific community needs to face in the coming years in order to achieve its ultimate goal of developing intelligent robotic sonographer colleagues. These colleagues are expected to be capable of collaborating with human sonographers in dynamic environments to enhance both diagnostic and intraoperative imaging.},
	journal = {Medical Image Analysis},
	author = {Jiang, Zhongliang and Salcudean, Septimiu E. and Navab, Nassir},
	month = oct,
	year = {2023},
	pmid = {37541100},
	note = {Publisher: Elsevier},
	keywords = {Medical robotics, Robotic ultrasound, Ultrasound imaging, Compliant control, Learning from demonstrations, Orientation optimization, Path planning, Reinforcement learning, Robot learning, Robotic US, Teleoperated robotic ultrasound, Telesonography, Ultrasound imgaing quality, Ultrasound standard plane, Visual servoing},
	pages = {102878},
}

@article{tan_fully_2023,
	title = {Fully {Automatic} {Dual}-{Probe} {Lung} {Ultrasound} {Scanning} {Robot} for {Screening} {Triage}},
	volume = {70},
	issn = {15258955},
	doi = {10.1109/TUFFC.2022.3211532},
	abstract = {Two-dimensional lung ultrasound (LUS) has widely emerged as a rapid and noninvasive imaging tool for the detection and diagnosis of coronavirus disease 2019 (COVID-19). However, image differences will be magnified due to changes in ultrasound (US) imaging experience, such as US probe attitude control and force control, which will directly affect the diagnosis results. In addition, the risk of virus transmission between sonographer and patients is increased due to frequent physical contact. In this study, a fully automatic dual-probe US scanning robot for the acquisition of LUS images is proposed and developed. Furthermore, the trajectory was optimized based on the velocity look-ahead strategy, the stability of contact force of the system and the scanning efficiency were improved by 24.13\% and 29.46\%, respectively. Also, the control ability of the contact force of robotic automatic scanning was 34.14 times higher than that of traditional manual scanning, which significantly improves the smoothness of scanning. Importantly, there was no significant difference in image quality obtained by robotic automatic scanning and manual scanning. Furthermore, the scanning time for a single person is less than 4 min, which greatly improves the efficiency of screening triage of group COVID-19 diagnosis and suspected patients and reduces the risk of virus exposure and spread.},
	number = {9},
	journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
	author = {Tan, Jiyong and Li, Bing and Leng, Yuquan and Li, Yuanwei and Peng, Junhua and Wu, Jiayi and Luo, Baoming and Chen, Xinxing and Rong, Yiming and Fu, Chenglong},
	month = sep,
	year = {2023},
	pmid = {36191095},
	note = {Publisher: Institute of Electrical and Electronics Engineers Inc.},
	keywords = {Automatic scanning, coronavirus disease 2019 (COVID-19), dual probe, image quality, lung ultrasound (LUS)},
	pages = {975--988},
}

@article{zhang_visual_2023,
	title = {Visual {Perception} and {Convolutional} {Neural} {Network}-{Based} {Robotic} {Autonomous} {Lung} {Ultrasound} {Scanning} {Localization} {System}},
	volume = {70},
	issn = {15258955},
	doi = {10.1109/TUFFC.2023.3263514},
	abstract = {Under the situation of severe COVID-19 epidemic, lung ultrasound (LUS) has been proved to be an effective and convenient method to diagnose and evaluate the extent of respiratory disease. However, the traditional clinical ultrasound (US) scanning requires doctors not only to be in close contact with patients but also to have rich experience. In order to alleviate the shortage of medical resources and reduce the work stress and risk of infection for doctors, we propose a visual perception and convolutional neural network (CNN)-based robotic autonomous LUS scanning localization system to realize scanned target recognition, probe pose solution and movement, and the acquisition of US images. The LUS scanned targets are identified through the target segmentation and localization algorithm based on the improved CNN, which is using the depth camera to collect the image information; furthermore, the method based on multiscale compensation normal vector is used to solve the attitude of the probe; finally, a position control strategy based on force feedback is designed to optimize the position and attitude of the probe, which can not only obtain high-quality US images but also ensure the safety of patients and the system. The results of human LUS scanning experiment verify the accuracy and feasibility of the system. The positioning accuracy of the scanned targets is 15.63 ± 0.18 mm, and the distance accuracy and rotation angle accuracy of the probe position calculation are 6.38 ± 0.25 mm and 8.60° ± 2.29°, respectively. More importantly, the obtained high-quality US images can clearly capture the main pathological features of the lung. The system is expected to be applied in clinical practice.},
	number = {9},
	journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
	author = {Zhang, Boheng and Cong, Haibo and Shen, Yi and Sun, Mingjian},
	month = sep,
	year = {2023},
	pmid = {37015119},
	note = {Publisher: Institute of Electrical and Electronics Engineers Inc.},
	keywords = {Convolutional neural network (CNN), lung ultrasound (LUS) scanning, pose solution, target localization, visual perception},
	pages = {961--974},
}

@article{bi_machine_2024,
	title = {Machine {Learning} in {Robotic} {Ultrasound} {Imaging}: {Challenges} and {Perspectives}},
	volume = {7},
	issn = {2573-5144},
	url = {https://www.annualreviews.org/content/journals/10.1146/annurev-control-091523-100042},
	doi = {10.1146/ANNUREV-CONTROL-091523-100042/CITE/REFWORKS},
	abstract = {This article reviews recent advances in intelligent robotic ultrasound imaging systems. We begin by presenting the commonly employed robotic mechanisms and control techniques in robotic ultrasound imaging, along with their clinical applications. Subsequently, we focus on the deployment of machine learning techniques in the development of robotic sonographers, emphasizing crucial developments aimed at enhancing the intelligence of these systems. The methods for achieving autonomous action reasoning are categorized into two sets of approaches: those relying on implicit environmental data interpretation and those using explicit interpretation. Throughout this exploration, we also discuss practical challenges, including those related to the scarcity of medical data, the need for a deeper understanding of the physical aspects involved, and effective data representation approaches. We conclude by highlighting the open problems in the field and analyzing different possible perspectives on how the community could move forward in this research area.Expected final online publication date for the Annual Review of Control, Robotics, and Autonomous Systems, Volume 7 is May 2024. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.},
	number = {1},
	journal = {Annual Review of Control, Robotics, and Autonomous Systems},
	author = {Bi, Yuan and Jiang, Zhongliang and Duelmer, Felix and Huang, Dianye and Navab, Nassir},
	month = may,
	year = {2024},
	note = {Publisher: Annual Reviews},
}

@article{wang_application_2021,
	title = {Application of a {Robotic} {Tele}-{Echography} {System} for {COVID}-19 {Pneumonia}},
	volume = {40},
	issn = {1550-9613},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1002/jum.15406 https://onlinelibrary.wiley.com/doi/abs/10.1002/jum.15406 https://onlinelibrary.wiley.com/doi/10.1002/jum.15406},
	doi = {10.1002/JUM.15406},
	abstract = {To date, coronavirus disease 2019 (COVID-19) has infected millions of people worldwide. Ultrasound plays an indispensable role in the diagnosis, monitoring, and follow-up of patients with COVID-19. In this study, we used a robotic tele-echography system based on a 5G communication network for remote diagnosis. The system has great potential for lung, heart, and vasculature information, medical staff protection, and resource sharing, can be a valuable tool for treating patients during the pandemic, and can be expected to expand to more specialized fields.},
	number = {2},
	journal = {Journal of Ultrasound in Medicine},
	author = {Wang, Jing and Peng, Chengzhong and Zhao, Yan and Ye, Ruizhong and Hong, Jun and Huang, Haijun and Chen, Legao},
	month = feb,
	year = {2021},
	pmid = {32725833},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {19, COVID, medical robotics, ultrasound, coronavirus, pneumonia},
	pages = {385--390},
}

@article{mento_ultrasound_2023,
	title = {Ultrasound multifrequency strategy to estimate the lung surface roughness, in silico and in vitro results},
	volume = {135},
	issn = {0041-624X},
	doi = {10.1016/J.ULTRAS.2023.107143},
	abstract = {Lung ultrasound (LUS) is an important imaging modality to assess the state of the lung surface. Nevertheless, LUS is limited to the visual evaluation of imaging artifacts, especially the vertical ones. These artifacts are observed in pathologies characterized by a reduction of dimensions of air-spaces (alveoli). In contrast, there exist pathologies, such as chronic obstructive pulmonary disease (COPD), in which an enlargement of air-spaces can occur, which causes the lung surface to behave essentially as a perfect reflector, thus not allowing ultrasound penetration. This characteristic high reflectivity could be exploited to characterize the lung surface. Specifically, air-spaces of different sizes could cause the lung surface to have a different roughness, whose estimation could provide a way to assess the state of the lung surface. In this study, we present a quantitative multifrequency approach aiming at estimating the lung surface's roughness by measuring image intensity variations along the lung surface as a function of frequency. This approach was tested both in silico and in vitro, and it showed promising results. For the in vitro experiments, radiofrequency (RF) data were acquired from a novel experimental model. The results showed consistency between in silico and in vitro experiments.},
	journal = {Ultrasonics},
	author = {Mento, Federico and Perini, Matteo and Malacarne, Ciro and Demi, Libertario},
	month = dec,
	year = {2023},
	pmid = {37647701},
	note = {Publisher: Elsevier},
	keywords = {In silico, In vitro, Multifrequency analysis, Quantitative Lung Ultrasound (LUS)},
	pages = {107143},
}

@article{demi_new_2023,
	title = {New {International} {Guidelines} and {Consensus} on the {Use} of {Lung} {Ultrasound}},
	volume = {42},
	issn = {1550-9613},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1002/jum.16088 https://onlinelibrary.wiley.com/doi/abs/10.1002/jum.16088 https://onlinelibrary.wiley.com/doi/10.1002/jum.16088},
	doi = {10.1002/JUM.16088},
	abstract = {Following the innovations and new discoveries of the last 10 years in the field of lung ultrasound (LUS), a multidisciplinary panel of international LUS experts from six countries and from different fields (clinical and technical) reviewed and updated the original international consensus for point-of-care LUS, dated 2012. As a result, a total of 20 statements have been produced. Each statement is complemented by guidelines and future developments proposals. The statements are furthermore classified based on their nature as technical (5), clinical (11), educational (3), and safety (1) statements.},
	number = {2},
	journal = {Journal of Ultrasound in Medicine},
	author = {Demi, Libertario and Wolfram, Frank and Klersy, Catherine and Silvestri, Annalisa De and Ferretti, Virginia Valeria and Muller, Marie and Miller, Douglas and Feletti, Francesco and Wełnicki, Marcin and Buda, Natalia and Skoczylas, Agnieszka and Pomiecko, Andrzej and Damjanovic, Domagoj and Olszewski, Robert and Kirkpatrick, Andrew W. and Breitkreutz, Raoul and Mathis, Gebhart and Soldati, Gino and Smargiassi, Andrea and Inchingolo, Riccardo and Perrone, Tiziano},
	month = feb,
	year = {2023},
	pmid = {35993596},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {19, COVID, lung ultrasound, 2, A, artificial intelligence, B, CoV, lines, lung ultrasound protocols, lung ultrasound standardization, LUS safety assurance, point of care ultrasound, post, quantitative ultrasound, SARS, sonographic interstitial syndrome, vertical artifacts},
	pages = {309--344},
}

@article{ma_guiding_2024,
	title = {Guiding the {Last} {Centimeter}: {Novel} {Anatomy}-{Aware} {Probe} {Servoing} for {Standardized} {Imaging} {Plane} {Navigation} in {Robotic} {Lung} {Ultrasound}},
	url = {https://arxiv.org/abs/2406.11523v1},
	abstract = {Navigating the ultrasound (US) probe to the standardized imaging plane (SIP) for image acquisition is a critical but operator-dependent task in conventional freehand diagnostic US. Robotic US systems (RUSS) offer the potential to enhance imaging consistency by leveraging real-time US image feedback to optimize the probe pose, thereby reducing reliance on operator expertise. However, determining the proper approach to extracting generalizable features from the US images for probe pose adjustment remain challenging. In this work, we propose a SIP navigation framework for RUSS, exemplified in the context of robotic lung ultrasound (LUS). This framework facilitates automatic probe adjustment when in proximity to the SIP. This is achieved by explicitly extracting multiple anatomical features presented in real-time LUS images and performing non-patient-specific template matching to generate probe motion towards the SIP using image-based visual servoing (IBVS). This framework is further integrated with the active-sensing end-effector (A-SEE), a customized robot end-effector that leverages patient external body geometry to maintain optimal probe alignment with the contact surface, thus preserving US signal quality throughout the navigation. The proposed approach ensures procedural interpretability and inter-patient adaptability. Validation is conducted through anatomy-mimicking phantom and in-vivo evaluations involving five human subjects. The results show the framework's high navigation precision with the probe correctly located at the SIP for all cases, exhibiting positioning error of under 2 mm in translation and under 2 degree in rotation. These results demonstrate the navigation process's capability to accomondate anatomical variations among patients.},
	author = {Ma, Xihan and Zeng, Mingjie and Hill, Jeffrey C. and Hoffmann, Beatrice and Zhang, Ziming and Zhang, Haichong K.},
	month = jun,
	year = {2024},
}

@inproceedings{bal_curvature_2023,
	title = {A {Curvature} and {Trajectory} {Optimization}-based {3D} {Surface} {Reconstruction} {Pipeline} for {Ultrasound} {Trajectory} {Generation}},
	url = {https://ieeexplore.ieee.org/document/10161513/?arnumber=10161513},
	doi = {10.1109/ICRA48891.2023.10161513},
	abstract = {Ultrasound scanning is an efficient imaging modality preferred for quick medical procedures. However, due to the lack of skilled sonographers, researchers have developed many Robotic Ultrasound System (RUS) prototypes for various procedures. Most of these systems have a human-in-the-loop and require an expert to point the robot to the region of the subject to be scanned. Only a few systems try to incorporate some knowledge from the exterior shape of the subject for ultrasound scanning. Accurate 3D surface reconstruction of a patient's exterior can enable an RUS to perceive subjects more like a clinician would. It can help localize the subject for the robot while eliminating input from an expert. Ultrasound scanning trajectories can be better planned if the RUS first detects critical regions on the surface of the subject and corresponding curvatures. We use an RGB-D sensor to acquire point clouds representing the 3D surface of the subject, which in the present work is for a lower-torso leg phantom. A consolidated pipeline for creating an optimized 3D surface reconstruction of a subject is presented and is used to autonomously identify a region of interest for scanning femoral vessels with an ultrasound probe. To make our system more robust to inter-subject variations in shape and size, we incorporate a trajectory optimization module of the RUS-mounted RGB-D sensor. To this end, we introduce a comprehensive evaluation score to quantify the quality of point cloud reconstructions. The resulting improvements in 3D surface scanning and reconstruction enable near-automation in generating ultrasound scanning trajectories for femoral vessels. Our pipeline produces ultrasound images with an average ZNCC score of 0.86 and our 3D point cloud reconstructions are accurate up to le-5 m from a ground-truth high-resolution CT scan.},
	urldate = {2024-07-18},
	booktitle = {2023 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Bal, Ananya and Gupta, Ashutosh and Abhimanyu, Fnu and Galeotti, John and Choset, Howie},
	month = may,
	year = {2023},
	keywords = {Ultrasonic imaging, Three-dimensional displays, Legged locomotion, Point cloud compression, Pipelines, Shape, Surface reconstruction},
	pages = {2724--2730},
	file = {IEEE Xplore Abstract Record:/home/giovanniperantoni/Zotero/storage/2B24JL3G/10161513.html:text/html;IEEE Xplore Full Text PDF:/home/giovanniperantoni/Zotero/storage/IIJC2Z2J/Bal et al. - 2023 - A Curvature and Trajectory Optimization-based 3D S.pdf:application/pdf},
}

@article{soldati_proposal_2020-1,
	title = {Proposal for {International} {Standardization} of the {Use} of {Lung} {Ultrasound} for {Patients} {With} {COVID}-19: {A} {Simple}, {Quantitative}, {Reproducible} {Method}},
	volume = {39},
	issn = {1550-9613},
	shorttitle = {Proposal for {International} {Standardization} of the {Use} of {Lung} {Ultrasound} for {Patients} {With} {COVID}-19},
	doi = {10.1002/jum.15285},
	abstract = {Growing evidence is showing the usefulness of lung ultrasound in patients with the 2019 new coronavirus disease (COVID-19). Severe acute respiratory syndrome coronavirus 2 has now spread in almost every country in the world. In this study, we share our experience and propose a standardized approach to optimize the use of lung ultrasound in patients with COVID-19. We focus on equipment, procedure, classification, and data sharing.},
	language = {eng},
	number = {7},
	journal = {Journal of Ultrasound in Medicine: Official Journal of the American Institute of Ultrasound in Medicine},
	author = {Soldati, Gino and Smargiassi, Andrea and Inchingolo, Riccardo and Buonsenso, Danilo and Perrone, Tiziano and Briganti, Domenica Federica and Perlini, Stefano and Torri, Elena and Mariani, Alberto and Mossolani, Elisa Eleonora and Tursi, Francesco and Mento, Federico and Demi, Libertario},
	month = jul,
	year = {2020},
	pmid = {32227492},
	pmcid = {PMC7228287},
	keywords = {lung ultrasound, scoring system, Ultrasonography, COVID-19, point-of-care ultrasound, Anatomic Landmarks, Artificial Intelligence, Betacoronavirus, Coronavirus Infections, Databases, Factual, Forecasting, Humans, Image Processing, Computer-Assisted, Internationality, Lung, Pandemics, Pneumonia, Viral, Point-of-Care Systems, Reproducibility of Results, SARS-CoV-2},
	pages = {1413--1419},
	file = {Full Text:/home/giovanniperantoni/Zotero/storage/GPWHACH5/Soldati et al. - 2020 - Proposal for International Standardization of the .pdf:application/pdf},
}

@article{vinter-hviid_safe_2024,
	title = {Safe contact-based robot active search using {Bayesian} optimization and control barrier functions},
	volume = {11},
	issn = {2296-9144},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11089096/},
	doi = {10.3389/frobt.2024.1344367},
	abstract = {In robotics, active exploration and learning in uncertain environments must take into account safety, as the robot may otherwise damage itself or its surroundings. This paper presents a method for safe active search using Bayesian optimization and control barrier functions. As robot paths undertaken during sampling are continuous, we consider an informative continuous expected improvement acquisition function. To safely bound the contact forces between the robot and its surroundings, we leverage exponential control barrier functions, utilizing the derivative of the force in the contact model to increase robustness to uncertainty in the contact boundary. Our approach is demonstrated on a fully autonomous robot for ultrasound scanning of rheumatoid arthritis (RA). Here, active search is a critical component of ensuring high image quality. Furthermore, bounded contact forces between the ultrasound probe and the patient ensure patient safety and better scan quality. To the best of our knowledge, our results are both the first demonstration of safe active search on a fully autonomous robot for ultrasound scanning of rheumatoid arthritis and the first experimental evaluation of bounding contact forces in the context of medical robotics using control barrier functions. The results show that when search time is limited to less than 60 s, informative continuous expected improvement leads to a 92\% success, a 13\% improvement compared to expected improvement. Meanwhile, exponential control barrier functions can limit the force applied by the robot to under 5 N, even in cases where the contact boundary is specified incorrectly by −1 or +4 mm.},
	urldate = {2024-08-01},
	journal = {Frontiers in Robotics and AI},
	author = {Vinter-Hviid, Frederik and Sloth, Christoffer and Savarimuthu, Thiusius Rajeeth and Iturrate, Iñigo},
	month = apr,
	year = {2024},
	pmid = {38741717},
	pmcid = {PMC11089096},
	pages = {1344367},
	file = {PubMed Central Full Text PDF:/home/giovanniperantoni/Zotero/storage/G8WDLQNP/Vinter-Hviid et al. - 2024 - Safe contact-based robot active search using Bayes.pdf:application/pdf},
}
@inproceedings{shahbazi_dual-user_2013,
	title = {A dual-user teleoperated system with {Virtual} {Fixtures} for robotic surgical training},
	url = {https://ieeexplore.ieee.org/document/6631088/?arnumber=6631088},
	doi = {10.1109/ICRA.2013.6631088},
	abstract = {This paper proposes a teleoperated dual-user system incorporating Virtual Fixtures (VFs) that allows concurrent performance of a robotic surgical task by an expert and a trainee. In order to guide the trainee through the procedure, an adaptive VF is created in the trainee's workspace according to the motion generated by the expert who is performing the surgery at the same time. The VF gets adaptively adjusted based on the level of expertise the trainee shows during the surgery. In addition, the trainee's level of expertise is used to adaptively adjust the dual-user dominance factor in an online fashion, which gives the trainee some authority over the task based on his/her skill level. To quantify the trainee's expertise level, a performance measure is proposed, based on the force generated by the VF. Three performance measures from the literature are also used. To satisfy the desired objectives of the proposed system, an impedance-based control methodology is adopted. Stability of the closed-loop system is investigated using the small-gain theorem. A sufficient stability condition is derived that guarantees stability in the presence of time-varying communication delay. Experimental results are given to validate the performance of the system.},
	urldate = {2024-08-02},
	booktitle = {2013 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Shahbazi, Mahya and Atashzar, S. Farokh and Patel, Rajni V.},
	month = may,
	year = {2013},
	note = {ISSN: 1050-4729},
	keywords = {Dual-User System, Fixtures, Force, Measurement, Robotic Surgical Training, Robots, Stability analysis, Surgery, Teleoperation, Training, Virtual Fixture},
	pages = {3639--3644},
	file = {IEEE Xplore Abstract Record:/home/giovanniperantoni/Zotero/storage/5S7QRZU2/6631088.html:text/html;IEEE Xplore Full Text PDF:/home/giovanniperantoni/Zotero/storage/LEYXQFAP/Shahbazi et al. - 2013 - A dual-user teleoperated system with Virtual Fixtu.pdf:application/pdf},
}
