

@misc{rosemberg1992use,
	title = {The {Use} of {Virtual} {Fixtures} as {Perceptual} {Overlays} to {Enhance} {Operator} {Performance} in {Remote} {Environments}.},
	url = {https://apps.dtic.mil/sti/citations/ADA292450},
	urldate = {2024-08-26},
	file = {The Use of Virtual Fixtures as Perceptual Overlays to Enhance Operator Performance in Remote Environments.},
    author = {Rosenberg, Louis B.}
}
@inproceedings{ryden_forbidden-region_2012,
	title = {Forbidden-region virtual fixtures from streaming point clouds: {Remotely} touching and protecting a beating heart},
	shorttitle = {Forbidden-region virtual fixtures from streaming point clouds},
	url = {https://ieeexplore.ieee.org/document/6386012/?arnumber=6386012},
	doi = {10.1109/IROS.2012.6386012},
	abstract = {Several established methods for remote touching using non-contact sensors exist. Applications for these methods are primarily within the field of robotic teleoperation. In surgical robotics it would be useful to not only touch, but also be able to maintain a distance from a certain organ. The latter can be done using non-contact sensors such as cameras. The novelty in this paper is the idea of combining forbidden-region virtual fixtures with haptic rendering from streaming point clouds. This is then used to protect as well as remotely touch a beating heart without any a priori knowledge of the heart geometry (such as from CT/MR scans).},
	urldate = {2024-08-08},
	booktitle = {2012 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Rydén, Fredrik and Chizeck, Howard Jay},
	month = oct,
	year = {2012},
	note = {ISSN: 2153-0866},
	keywords = {Force, Haptic interfaces, Heart, Hip, Rendering (computer graphics), Robots, Vectors},
	pages = {3308--3313},
	file = {IEEE Xplore Abstract Record:/home/hydran00/Zotero/storage/L4HEVING/6386012.html:text/html;IEEE Xplore Full Text PDF:/home/hydran00/Zotero/storage/GV9U84SS/Rydén and Chizeck - 2012 - Forbidden-region virtual fixtures from streaming p.pdf:application/pdf},
}

@misc{li_anatomical_2020,
	title = {Anatomical {Mesh}-{Based} {Virtual} {Fixtures} for {Surgical} {Robots}},
	url = {http://arxiv.org/abs/2006.02415},
	abstract = {This paper presents a dynamic constraint formulation to provide protective virtual ﬁxtures of 3D anatomical structures from polygon mesh representations. The proposed approach can anisotropically limit the tool motion of surgical robots without any assumption of the local anatomical shape close to the tool. Using a bounded search strategy and Principle Directed tree, the proposed system can run efﬁciently at 180 Hz for a mesh object containing 989,376 triangles and 493,460 vertices. The proposed algorithm has been validated in both simulation and skull cutting experiments. The skull cutting experiment setup uses a novel piezoelectric bone cutting tool designed for the da Vinci research kit. The result shows that the virtual ﬁxture assisted teleoperation has statistically signiﬁcant improvements in the cutting path accuracy and penetration depth control. The code has been made publicly available at https://github.com/mli0603/PolygonMeshVirtualFixture.},
	language = {en},
	urldate = {2024-08-08},
	publisher = {arXiv},
	author = {Li, Zhaoshuo and Gordon, Alex and Looi, Thomas and Drake, James and Forrest, Christopher and Taylor, Russell H.},
	month = jul,
	year = {2020},
	note = {arXiv:2006.02415 [cs, eess]},
	keywords = {Computer Science - Robotics, Electrical Engineering and Systems Science - Systems and Control},
	file = {Li et al. - 2020 - Anatomical Mesh-Based Virtual Fixtures for Surgica.pdf:/home/hydran00/Zotero/storage/TZQ753H3/Li et al. - 2020 - Anatomical Mesh-Based Virtual Fixtures for Surgica.pdf:application/pdf},
}

@misc{huang_robot-assisted_2024,
	title = {Robot-{Assisted} {Deep} {Venous} {Thrombosis} {Ultrasound} {Examination} using {Virtual} {Fixture}},
	url = {http://arxiv.org/abs/2401.02539},
	abstract = {Deep Venous Thrombosis (DVT) is a common vascular disease with blood clots inside deep veins, which may block blood flow or even cause a life-threatening pulmonary embolism. A typical exam for DVT using ultrasound (US) imaging is by pressing the target vein until its lumen is fully compressed. However, the compression exam is highly operator-dependent. To alleviate intra- and inter-variations, we present a robotic US system with a novel hybrid force motion control scheme ensuring position and force tracking accuracy, and soft landing of the probe onto the target surface. In addition, a path-based virtual fixture is proposed to realize easy human-robot interaction for repeat compression operation at the lesion location. To ensure the biometric measurements obtained in different examinations are comparable, the 6D scanning path is determined in a coarseto-fine manner using both an external RGBD camera and US images. The RGBD camera is first used to extract a rough scanning path on the object. Then, the segmented vascular lumen from US images are used to optimize the scanning path to ensure the visibility of the target object. To generate a continuous scan path for developing virtual fixtures, an arc-length based path fitting model considering both position and orientation is proposed. Finally, the whole system is evaluated on a human-like arm phantom with an uneven surface. The code1 and intuitive demonstration video2 can be publicly accessed.},
	language = {en},
	urldate = {2024-08-08},
	publisher = {arXiv},
	author = {Huang, Dianye and Yang, Chenguang and Zhou, Mingchuan and Karlas, Angelos and Navab, Nassir and Jiang, Zhongliang},
	month = jan,
	year = {2024},
	note = {arXiv:2401.02539 [cs]},
	keywords = {Computer Science - Robotics, Computer Science - Computer Vision and Pattern Recognition},
	file = {Huang et al. - 2024 - Robot-Assisted Deep Venous Thrombosis Ultrasound E.pdf:/home/hydran00/Zotero/storage/JARGZRCP/Huang et al. - 2024 - Robot-Assisted Deep Venous Thrombosis Ultrasound E.pdf:application/pdf},
}

@article{bettini_vision-assisted_2004,
	title = {Vision-assisted control for manipulation using virtual fixtures},
	volume = {20},
	issn = {1941-0468},
	url = {https://ieeexplore.ieee.org/document/1362691},
	doi = {10.1109/TRO.2004.829483},
	abstract = {We present the design and implementation of a vision-based system for cooperative manipulation at millimeter to micrometer scales. The system is based on an admittance control algorithm that implements a broad class of guidance modes called virtual fixtures. A virtual fixture, like a real fixture, limits the motion of a tool to a prescribed class or range of motions. We describe how both hard (unyielding) and soft (yielding) virtual fixtures can be implemented in this control framework. We then detail the construction of virtual fixtures for point positioning and curve following as well as extensions of these to tubes, cones, and sequences thereof. We also describe an implemented system using the JHU Steady Hand Robot. The system uses computer vision as a sensor for providing a reference trajectory, and the virtual fixture control algorithm then provides haptic feedback to implemented direct, shared manipulation. We provide extensive experimental results detailing both system performance and the effects of virtual fixtures on human speed and accuracy.},
	number = {6},
	urldate = {2024-08-07},
	journal = {IEEE Transactions on Robotics},
	author = {Bettini, A. and Marayong, P. and Lang, S. and Okamura, A.M. and Hager, G.D.},
	month = dec,
	year = {2004},
	note = {Conference Name: IEEE Transactions on Robotics},
	keywords = {Haptic interfaces, Admittance, Computer vision, Control systems, Feedback, Fixtures, Human–machine systems, Humans, robot control, Robot sensing systems, Sensor systems, System performance, virtual fixtures, visual servoing},
	pages = {953--966},
	file = {IEEE Xplore Abstract Record:/home/hydran00/Zotero/storage/DTF3RSX2/1362691.html:text/html;IEEE Xplore Full Text PDF:/home/hydran00/Zotero/storage/KEAFN2ZT/Bettini et al. - 2004 - Vision-assisted control for manipulation using vir.pdf:application/pdf},
}

@article{selvaggio_passive_2018,
	title = {Passive {Virtual} {Fixtures} {Adaptation} in {Minimally} {Invasive} {Robotic} {Surgery}},
	volume = {3},
	issn = {2377-3766},
	url = {https://ieeexplore.ieee.org/document/8392699},
	doi = {10.1109/LRA.2018.2849876},
	abstract = {During robot-aided surgical interventions, the surgeon can be benefitted from the application of virtual fixtures (VFs). Though very effective, this technique is very often not practicable in unstructured surgical environments. In order to comply with the environmental deformation, both the VF geometry and the constraint enforcement parameters need to be online defined/adapted. This letter proposes a strategy for an effective use of VF assistance in minimally invasive robotic surgical tasks. An online VF generation technique based on the interaction force measurements is presented. Pose and geometry adaptations of the VF are considered. Passivity of the overall system is guaranteed by using energy tanks passivity-based control. The proposed method is validated through experiments on the da Vinci Research Kit.},
	number = {4},
	urldate = {2024-08-07},
	journal = {IEEE Robotics and Automation Letters},
	author = {Selvaggio, Mario and Fontanelli, Giuseppe Andrea and Ficuciello, Fanny and Villani, Luigi and Siciliano, Bruno},
	month = oct,
	year = {2018},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {Force, Robots, compliance and impedance control, Geometry, Impedance, laparoscopy, physical human-robot interaction, Splines (mathematics), Surgery, Surgical robotics, Task analysis},
	pages = {3129--3136},
	file = {IEEE Xplore Abstract Record:/home/hydran00/Zotero/storage/872RVUUZ/8392699.html:text/html;IEEE Xplore Full Text PDF:/home/hydran00/Zotero/storage/NUHGBYAM/Selvaggio et al. - 2018 - Passive Virtual Fixtures Adaptation in Minimally I.pdf:application/pdf},
}

@article{bowyer_active_2014,
	title = {Active {Constraints}/{Virtual} {Fixtures}: {A} {Survey}},
	volume = {30},
	issn = {1941-0468},
	shorttitle = {Active {Constraints}/{Virtual} {Fixtures}},
	url = {https://ieeexplore.ieee.org/document/6634270},
	doi = {10.1109/TRO.2013.2283410},
	abstract = {Active constraints, also known as virtual fixtures, are high-level control algorithms which can be used to assist a human in man-machine collaborative manipulation tasks. The active constraint controller monitors the robotic manipulator with respect to the environment and task, and anisotropically regulates the motion to provide assistance. The type of assistance offered by active constraints can vary, but they are typically used to either guide the user along a task-specific pathway or limit the user to within a “safe” region. There are several diverse methods described within the literature for applying active constraints, and these are surveyed within this paper. The active constraint research is described and compared using a simple generalized framework, which consists of three primary processes: 1) constraint definition, 2) constraint evaluation, and 3) constraint enforcement. All relevant research approaches for each of these processes, found using search terms associated to “virtual fixture,” “active constraint” and “motion constraint,” are presented.},
	number = {1},
	urldate = {2024-08-07},
	journal = {IEEE Transactions on Robotics},
	author = {Bowyer, Stuart A. and Davies, Brian L. and Rodriguez y Baena, Ferdinando},
	month = feb,
	year = {2014},
	note = {Conference Name: IEEE Transactions on Robotics},
	keywords = {Admittance, Robot sensing systems, Geometry, Impedance, Surgery, Haptics and haptic interfaces, impedance/admittance control, Manipulators, medical robots and systems, physical human–robot interaction, telerobotics},
	pages = {138--157},
	file = {IEEE Xplore Abstract Record:/home/hydran00/Zotero/storage/BT7IXHKA/6634270.html:text/html;IEEE Xplore Full Text PDF:/home/hydran00/Zotero/storage/8Y5EFI26/Bowyer et al. - 2014 - Active ConstraintsVirtual Fixtures A Survey.pdf:application/pdf},
}

@article{moccia_vision-based_2020,
	title = {Vision-{Based} {Dynamic} {Virtual} {Fixtures} for {Tools} {Collision} {Avoidance} in {Robotic} {Surgery}},
	volume = {5},
	issn = {2377-3766},
	url = {https://ieeexplore.ieee.org/document/8972577},
	doi = {10.1109/LRA.2020.2969941},
	abstract = {In robot-aided surgery, during the execution of typical bimanual procedures such as dissection, surgical tools can collide and create serious damage to the robot or tissues. The da Vinci robot is one of the most advanced and certainly the most widespread robotic system dedicated to minimally invasive surgery. Although the procedures performed by da Vinci-like surgical robots are teleoperated, potential collisions between surgical tools are a very sensitive issue declared by surgeons. Shared control techniques based on Virtual Fixtures (VF) can be an effective way to help the surgeon prevent tools collision. This letter presents a surgical tools collision avoidance method that uses Forbidden Region Virtual Fixtures. Tool clashing is avoided by rendering a repulsive force to the surgeon. To ensure the correct definition of the VF, a marker-less tool tracking method, using deep neural network architecture for tool segmentation, is adopted. The use of direct kinematics for tools collision avoidance is affected by tools position error introduced by robot component elasticity during tools interaction with the environment. On the other hand, kinematics information can help in case of occlusions of the camera. Therefore, this work proposes an Extended Kalman Filter (EKF) for pose estimation which ensures a more robust application of VF on the tool, coupling vision and kinematics information. The entire pipeline is tested in different tasks using the da Vinci Research Kit system.},
	number = {2},
	urldate = {2024-08-07},
	journal = {IEEE Robotics and Automation Letters},
	author = {Moccia, Rocco and Iacono, Cristina and Siciliano, Bruno and Ficuciello, Fanny},
	month = apr,
	year = {2020},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {Robots, virtual fixtures, Surgery, Surgical robotics, Cameras, collision avoidance, Collision avoidance, haptic feedback, Image segmentation, Kinematics, surgical tool tracking, Tools},
	pages = {1650--1655},
	file = {IEEE Xplore Full Text PDF:/home/hydran00/Zotero/storage/SZZ2YXVR/Moccia et al. - 2020 - Vision-Based Dynamic Virtual Fixtures for Tools Co.pdf:application/pdf},
}

@article{shi_dynamic_2024,
	title = {Dynamic {Virtual} {Fixture} {Generation} {Based} on {Intra}-{Operative} {3D} {Image} {Feedback} in {Robot}-{Assisted} {Minimally} {Invasive} {Thoracic} {Surgery}},
	volume = {24},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/24/2/492},
	doi = {10.3390/s24020492},
	abstract = {This paper proposes a method for generating dynamic virtual fixtures with real-time 3D image feedback to facilitate human–robot collaboration in medical robotics. Seamless shared control in a dynamic environment, like that of a surgical field, remains challenging despite extensive research on collaborative control and planning. To address this problem, our method dynamically creates virtual fixtures to guide the manipulation of a trocar-placing robot arm using the force field generated by point cloud data from an RGB-D camera. Additionally, the “view scope” concept selectively determines the region for computational points, thereby reducing computational load. In a phantom experiment for robot-assisted port incision in minimally invasive thoracic surgery, our method demonstrates substantially improved accuracy for port placement, reducing error and completion time by 50\% (p=1.06×10−2) and 35\% (p=3.23×10−2), respectively. These results suggest that our proposed approach is promising in improving surgical human–robot collaboration.},
	language = {en},
	number = {2},
	urldate = {2024-08-07},
	journal = {Sensors},
	author = {Shi, Yunze and Zhu, Peizhang and Wang, Tengyue and Mai, Haonan and Yeh, Xiyang and Yang, Liangjing and Wang, Jingfan},
	month = jan,
	year = {2024},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {virtual fixtures, 3D image-guided robots, human–robot collaboration, virtual force field},
	pages = {492},
	file = {Full Text PDF:/home/hydran00/Zotero/storage/FE492NY3/Shi et al. - 2024 - Dynamic Virtual Fixture Generation Based on Intra-.pdf:application/pdf},
}

@misc{li_anatomical_2020-1,
	title = {Anatomical {Mesh}-{Based} {Virtual} {Fixtures} for {Surgical} {Robots}},
	url = {http://arxiv.org/abs/2006.02415},
	abstract = {This paper presents a dynamic constraint formulation to provide protective virtual ﬁxtures of 3D anatomical structures from polygon mesh representations. The proposed approach can anisotropically limit the tool motion of surgical robots without any assumption of the local anatomical shape close to the tool. Using a bounded search strategy and Principle Directed tree, the proposed system can run efﬁciently at 180 Hz for a mesh object containing 989,376 triangles and 493,460 vertices. The proposed algorithm has been validated in both simulation and skull cutting experiments. The skull cutting experiment setup uses a novel piezoelectric bone cutting tool designed for the da Vinci research kit. The result shows that the virtual ﬁxture assisted teleoperation has statistically signiﬁcant improvements in the cutting path accuracy and penetration depth control. The code has been made publicly available at https://github.com/mli0603/PolygonMeshVirtualFixture.},
	language = {en},
	urldate = {2024-08-07},
	publisher = {arXiv},
	author = {Li, Zhaoshuo and Gordon, Alex and Looi, Thomas and Drake, James and Forrest, Christopher and Taylor, Russell H.},
	month = jul,
	year = {2020},
	note = {arXiv:2006.02415 [cs, eess]},
	keywords = {Computer Science - Robotics, Electrical Engineering and Systems Science - Systems and Control},
	file = {Li et al. - 2020 - Anatomical Mesh-Based Virtual Fixtures for Surgica.pdf:/home/hydran00/Zotero/storage/PW59CM4I/Li et al. - 2020 - Anatomical Mesh-Based Virtual Fixtures for Surgica.pdf:application/pdf},
}